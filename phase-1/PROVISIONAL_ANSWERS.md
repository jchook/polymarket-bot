Provisional answers to open questions (latency is the primary constraint throughout):

- Data stack: Enable TimescaleDB on Postgres now; hypertables for ticks/price_changes and continuous aggregates later. Redis used for hot state and queues only; avoid any unnecessary cross-region hops.
- Polymarket coverage: Start with targeted condition_ids for BTC-linked markets; subscribe to `clob_market.price_changes` for those asset_ids. Maintain per-asset best bid/ask state (bid, ask, ts, hash); define `q_t = mid(bid, ask)` only when both are present and fresh. If stale/missing, mark row invalid for training/backtest. Add `agg_orderbook` only if we need depth/imbalance signals and can process without adding material latency.
- Coinbase feed: Use Advanced Trade public WS via `WebsocketClient` (topic `ticker` or `level2` with `product_ids: ['BTC-USD']`) and enable built-in auto-reconnect/resubscribe. Subscribe to `heartbeats` alongside market topics; alert if heartbeats/data silent >5s. Spread high-volume products across separate WS connections; send unique subscription per channel/product. Drop/flag ticks older than 3s. Co-locate feed consumer near Coinbase edge to cut RTT; consider redundant secondary spot feed (e.g., Kraken/Binance) later for health/lag detection.
- Feature anchors: Prefer rolling anchors for stability: `x1_t = ln(S_t / S_{t-60s})` (try 30s/120s too). Keep `x2_t = EMA_fast - EMA_slow`, `x3_t = rolling vol`. Optional feature: `x_window = ln(S_t / S_windowStart)` only if window start is reliably known. Keep feature calc in-memory with minimal serialization.
- Feature params: Initial EMAs 10s/60s; volatility lookback 120s on log returns; consider order book imbalance as an optional factor only if it doesn’t degrade latency budget.
- Δ_SPD thresholds: Use dynamic thresholds: `δ_enter = max(0.01, 2*spread)` with spread = bestAsk - bestBid; `δ_exit = max(0.005, spread)`. Position cap 1–2% of bankroll per side, max inventory 3 legs per market; adjust post-backtest and scale with vol if needed.
- Regression data: Train on last 2–4 weeks; resample to 1s cadence aligning PM mid with nearest BTC mid where `|dt_ms| <= 250ms`; store `pm_ts`, `spot_ts`, `dt_ms`, and track dt histogram. Clamp `q_t` to [0.001, 0.999] before logit; winsorize outliers and drop rows with gaps >2s. Weight rows by liquidity quality (e.g., 1/(spread^2+ε) or size-based). Ensure training pipeline runs off-peak to avoid impacting live latency.
- Model lifecycle: Store β with version/timestamp and regularization meta (ridge λ) in strategy_params; refit daily with rolling window; validate on most recent day and roll forward only if R²/MAPE improve or stay stable. Hot-reload params without restart to avoid downtime.
- Backtest realism: Include fees per side (PM + exchange), dynamic slippage (≥ spread; 1–2 ticks baseline), 200–400ms latency plus queueing jitter (50–150ms with occasional spikes), 100–300ms clock skew tolerance; reject trades when spreads exceed configured max. Model partial fills: consume available size at price, remainder rests or reprices. Simulate cancel/replace delays explicitly.
- Execution rules: Express limits relative to book, not mid: BUY at `min(bestAsk, q_t + maxPaySlippage)`; SELL at `max(bestBid, q_t - maxPaySlippage)`. Prefer limit/IOC; cancel/replace every 1s if resting; circuit-breaker if fills diverge from expected price by >3 ticks or Δ_SPD flips sign. Co-locate order gateway; keep wire format minimal and avoid blocking calls in the hot path.
